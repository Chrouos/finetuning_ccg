{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light 資料分割完成！\n",
      "medium 資料分割完成！\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "# 定義不同級別的提示\n",
    "leight_prompt = textwrap.dedent(\"\"\"\n",
    "使用判決書填充JSON結構。要求如下:\n",
    "1. 以賠償給原告的數據填寫。\n",
    "2. 判決前的賠償金額需要包含：零件、材料、塗裝、烤漆。\n",
    "返回結果為一行JSON格式字串，無換行或特殊符號。\n",
    "\"\"\")\n",
    "\n",
    "medium_prompt = textwrap.dedent(\"\"\"\n",
    "根據給定的判決文檔填充JSON結構。要求如下:\n",
    "1. 以賠償給原告的數據填寫。\n",
    "2. 判決前的賠償金額需包含：零件、材料、工資、鈑金、塗裝、烤漆。\n",
    "3. 若無結果則留空白，如 {\"工資\": \"\"} \n",
    "4. 注意每日每月之單位，一個月為30天\n",
    "5. 每日工作收入改填寫每月工作收入\n",
    "返回結果為一行JSON格式字串，無換行或特殊符號。\n",
    "\"\"\")\n",
    "\n",
    "rule_level_list = {\n",
    "    'light': leight_prompt,\n",
    "    'medium': medium_prompt,\n",
    "}\n",
    "\n",
    "all_data_path = \"./finetuning_training_data_golden.jsonl\"\n",
    "\n",
    "# 讀取資料\n",
    "with open(all_data_path, 'r', encoding='utf-8') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "random.shuffle(data)\n",
    "\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(data) * split_ratio)\n",
    "\n",
    "# 分割資料\n",
    "train_data = data[:split_index]\n",
    "remaining_data = data[split_index:]\n",
    "val_test_split_index = int(len(remaining_data) * 0.5)\n",
    "\n",
    "val_data = remaining_data[:val_test_split_index]\n",
    "test_data = remaining_data[val_test_split_index:]\n",
    "\n",
    "def format_data(prompt, data_item):\n",
    "    formatted_text = f\"<s>[INST]{prompt}[/INST] [CONTENT]{data_item['input']}[/CONTENT] {data_item['output']}</s>\"\n",
    "    return {'text': formatted_text}\n",
    "\n",
    "for rule_level, prompt in rule_level_list.items():\n",
    "\n",
    "    # 定義目錄\n",
    "    dir_path = f\"./ccg/{rule_level}\"\n",
    "\n",
    "    # 檢查並創建目錄\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "    train_data_path = os.path.join(dir_path, \"train.jsonl\")\n",
    "    val_data_path = os.path.join(dir_path, \"valid.jsonl\")\n",
    "    test_data_path = os.path.join(dir_path, \"test.jsonl\")\n",
    "\n",
    "    # 在每個資料項目中加入 subject 並格式化\n",
    "    train_data_with_subject = [format_data(prompt, item) for item in train_data]\n",
    "    val_data_with_subject = [format_data(prompt, item) for item in val_data]\n",
    "    test_data_with_subject = [format_data(prompt, item) for item in test_data]\n",
    "\n",
    "    # 儲存 train 資料\n",
    "    with open(train_data_path, 'w', encoding='utf-8') as f:\n",
    "        for item in train_data_with_subject:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    # 儲存 valid 資料\n",
    "    with open(val_data_path, 'w', encoding='utf-8') as f:\n",
    "        for item in val_data_with_subject:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    # 儲存 test 資料\n",
    "    with open(test_data_path, 'w', encoding='utf-8') as f:\n",
    "        for item in test_data_with_subject:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    print(f\"{rule_level} 資料分割完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
